{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1910a06-e8a3-40ac-8201-ff70615b1ba4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generating An Instruction Dataset via Llama 3 and Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128651b-f326-4232-a994-42f38b7ed520",
   "metadata": {},
   "source": [
    "- This notebook uses an 8-billion-parameter Llama 3 model through ollama to generate a synthetic dataset using the \"hack\" proposed in the \"Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing\" paper ([https://arxiv.org/abs/2406.08464](https://arxiv.org/abs/2406.08464))\n",
    "\n",
    "- The generated dataset will be an instruction dataset with \"instruction\" and \"output\" field similar to what can be found in Alpaca:\n",
    "\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"instruction\": \"What is the atomic number of helium?\",\n",
    "    \"output\": \"The atomic number of helium is 2.\",\n",
    "},\n",
    "```\n",
    "\n",
    "- The code doesn't require a GPU and runs on a laptop (it was tested on a M3 MacBook Air)\n",
    "\n",
    "*Note that the instruction datasets created here are for educational purposes. However, it is the users' duty to ensure that their use adheres to the terms of the relevant licensing agreements with Meta AI's Llama 3.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63610acc-db94-437f-8d38-e99dca0299cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"tqdm\",    # Progress bar\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcdcb34-ac75-4f4f-9505-3ce0666c42d5",
   "metadata": {},
   "source": [
    "## Installing Ollama and Downloading Llama 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a092280-5462-4709-a3fe-8669a4a8a0a6",
   "metadata": {},
   "source": [
    "- Ollama is an application to run LLMs efficiently\n",
    "- It is a wrapper around [llama.cpp](https://github.com/ggerganov/llama.cpp), which implements LLMs in pure C/C++ to maximize efficiency\n",
    "- Note that it is a tool for using LLMs to generate text (inference), not training or finetuning LLMs\n",
    "- Prior to running the code below, install ollama by visiting [https://ollama.com](https://ollama.com) and following the instructions (for instance, clicking on the \"Download\" button and downloading the ollama application for your operating system)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558a522-650d-401a-84fc-9fd7b1f39da7",
   "metadata": {},
   "source": [
    "- For macOS and Windows users, click on the ollama application you downloaded; if it prompts you to install the command line usage, say \"yes\"\n",
    "- Linux users can use the installation command provided on the ollama website\n",
    "\n",
    "- In general, before we can use ollama from the command line, we have to either start the ollama application or run `ollama serve` in a separate terminal\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/Sangwan70/Building-an-LLM-From-Scratch/refs/heads/main/part_6/images/ollama-serve.webp?1\">\n",
    "\n",
    "\n",
    "- With the ollama application or `ollama serve` running, in a different terminal, on the command line, execute the following command to try out the 3-billion-parameter Llama 3.2 model (the model, which takes up 4.7 GB of storage space, will be automatically downloaded the first time you execute this command)\n",
    "\n",
    "```bash\n",
    "ollama run llama3.2\n",
    "```\n",
    "\n",
    "\n",
    "The output looks like as follows:\n",
    "\n",
    "```\n",
    "$ ollama run llama3.2\n",
    "pulling manifest \n",
    "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB                         \n",
    "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB                         \n",
    "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B                         \n",
    "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B                         \n",
    "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B                         \n",
    "verifying sha256 digest \n",
    "writing manifest \n",
    "removing any unused layers \n",
    "success \n",
    "```\n",
    "\n",
    "- Note that `llama3.2` refers to the instruction finetuned 3-billion-parameter Llama 3.2 model\n",
    "\n",
    "- After the download has been completed, you will see a command line prompt that allows you to chat with the model\n",
    "\n",
    "- Try a prompt like \"What do llamas eat?\", which should return an output similar to the following:\n",
    "\n",
    "```\n",
    "% ollama run llama3.2\n",
    ">>> What are the courses offered at Oracle University? \n",
    "Oracle University offers a wide range of courses and certifications in various areas, including:\n",
    "\n",
    "1. Oracle Database Administration:\n",
    " * Oracle Database: Essentials (10g/11g)\n",
    " * Oracle Database: Advanced (10g/11g)\n",
    " * Oracle Database: Performance Tuning\n",
    "2. Oracle E-Business Suite:\n",
    " * Oracle E-Business Suite: Essentials (12c/13c)\n",
    " * Oracle E-Business Suite: Advanced (12c/13c)\n",
    " * Oracle E-Business Suite: Implementation and Development\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5addcb-fc7d-455d-bee9-6cc7a0d684c7",
   "metadata": {},
   "source": [
    "- You can end this session using the input `/bye`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda155ee-cf36-44d3-b634-20ba8e1ca38a",
   "metadata": {},
   "source": [
    "## Using Ollama's REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89343a84-0ddc-42fc-bf50-298a342b93c0",
   "metadata": {},
   "source": [
    "- Now, an alternative way to interact with the model is via its REST API in Python via the following function\n",
    "- Before you run the next cells in this notebook, make sure that ollama is still running, as described above, via\n",
    "  - `ollama serve` in a terminal\n",
    "  - the ollama application\n",
    "- Next, run the following code cell to query the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16642a48-1cab-40d2-af08-ab8c2fbf5876",
   "metadata": {},
   "source": [
    "- First, let's try the API with a simple example to make sure it works as intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b0ba76-1fb1-4306-a7c2-8f3bb637ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "def query_model(prompt, model=\"llama3.2\", url=\"http://localhost:11434/api/chat\", role=\"user\"):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"seed\": 123,        # for deterministic responses\n",
    "        \"temperature\": 1.,   # for deterministic responses\n",
    "        \"top_p\": 1,         \n",
    "        \"messages\": [\n",
    "            {\"role\": role, \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fb61a4e-2706-431a-835e-7e472b42989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llamas are herbivores, which means they primarily eat plants and plant-based materials. Their diet typically consists of:\n",
      "\n",
      "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even aquatic plants.\n",
      "2. Hay: Hay is a staple in a llama's diet, especially during the winter months when other food sources may be scarce.\n",
      "3. Grains: Llamas can also eat grains like oats, barley, and corn, but these should not make up more than 10% of their diet.\n",
      "4. Browse: Browse refers to shrubs, leaves, and other woody vegetation that are high in fiber and nutrients. Llamas enjoy browsing on plants like alfalfa, clover, and sweetgum trees.\n",
      "5. Fruits and vegetables: In moderation, llamas can eat fruits and vegetables, such as apples, carrots, and squash.\n",
      "\n",
      "It's essential to note that llamas have a specific nutritional requirement, so it's best to provide them with a balanced diet that includes a mix of these food sources.\n",
      "\n",
      "Here are some guidelines for feeding llamas:\n",
      "\n",
      "* Provide at least 1-2% of their body weight in dry matter per day.\n",
      "* Offer fresh water at all times.\n",
      "* Limit grains and concentrate feeds, as they can lead to obesity and other health issues.\n",
      "* Avoid feeding llamas spoiled or moldy food.\n",
      "\n",
      "Consult with a veterinarian or a qualified llama breeder to determine the best diet for your llama based on their age, size, and individual needs.\n"
     ]
    }
   ],
   "source": [
    "result = query_model(\"What do Llamas eat?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c079c6c-5845-4b31-a648-060d0273cd1d",
   "metadata": {},
   "source": [
    "## Extract Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b09132-4a92-4492-9b67-24a644767498",
   "metadata": {},
   "source": [
    "- Now, let's use the \"hack\" proposed in the paper: we provide the empty prompt template `\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\"` prompt, which will cause the instruction-finetuned Llama 3 model to generate an instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7320a41-ed86-49e9-8eb1-5d609a82ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_instruction(text):\n",
    "    for content in text.split(\"\\n\"):\n",
    "        if content:\n",
    "            return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc41b72f-a8cf-4367-b0ca-0bf8c1f094fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been experiencing some issues with my computer's Wi-Fi connectivity. I'm having trouble connecting to a particular network. Here are the details of the issue:\n"
     ]
    }
   ],
   "source": [
    "query = \"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\"\n",
    "\n",
    "result = query_model(query, role=\"assistant\")\n",
    "instruction = extract_instruction(result)\n",
    "print(instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d04ba7-bffc-47f0-87dc-d60fc676b14a",
   "metadata": {},
   "source": [
    "- As we can see above, surprisingly, the model indeed generated an instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a4739-6f03-4092-a5c2-f57a0b6a4c4d",
   "metadata": {},
   "source": [
    "## Generate Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542f8d3-2db2-4a89-ae50-8825eb19d3b6",
   "metadata": {},
   "source": [
    "- Now, the next step is to create the corresponding response, which can be done by simply passing the instruction as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2349eb06-710f-4459-8a03-1a3b2e1e8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you troubleshoot your Wi-Fi connectivity issues. Please go ahead and share the details of the issue, such as:\n",
      "\n",
      "* The name or password of the network you're trying to connect to\n",
      "* What device (computer, phone, etc.) you're using to try and connect\n",
      "* Any error messages you've received when attempting to connect\n",
      "* What kind of Wi-Fi router you have and its make/model\n",
      "* If there are any other devices connected to the same network that are working fine\n",
      "\n",
      "The more information you can provide, the better I'll be able to assist you in resolving your issue.\n"
     ]
    }
   ],
   "source": [
    "response = query_model(instruction, role=\"user\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12cf92c-3272-4b36-ae30-d1135af56328",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470037f3-64f4-4465-9f00-55b69e883a04",
   "metadata": {},
   "source": [
    "- We can scale up this approach to an arbitrary number of data samples (you may want to apply some optional filtering length or quality (e.g., using another LLM to rate the generated data)\n",
    "- Below, we generate 5 synthetic instruction-response pairs, which takes about 3 minutes on an M3 MacBook Air\n",
    "- (To generate a dataset suitable for instruction finetuning, we want to increase this to at least 1k to 50k and perhaps run it on a GPU to generate the examples in a more timely fashion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b9e94ab-02ef-4372-91cd-60128159fd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:31<00:00,  6.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dataset_size = 5\n",
    "dataset = []\n",
    "\n",
    "for i in tqdm(range(dataset_size)):\n",
    "\n",
    "    result = query_model(query, role=\"assistant\")\n",
    "    instruction = extract_instruction(result)\n",
    "    response = query_model(instruction, role=\"user\")\n",
    "    entry = {\n",
    "        \"instruction\": instruction,\n",
    "        \"output\": response\n",
    "    }\n",
    "    dataset.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fdbc194-c12a-4138-96d1-51bf66ca1574",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"instruction-data-llama3_2-3b.json\", \"w\") as file:\n",
    "    json.dump(dataset, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4027ead-bba4-49b7-9965-47532c3fdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"instruction\": \"Hello! I need help with a math problem. Can you explain how to solve it?\",\n",
      "        \"output\": \"I'd be happy to help you with your math problem. What's the specific problem you're working on? Please share the numbers and the operation (addition, subtraction, multiplication, or division) involved, and I'll guide you through the solution step by step.\"\n",
      "    },\n",
      "    {\n",
      "        \"instruction\": \"I'm looking for information on the use of social media in the workplace. Here are some specific questions I'd like answers to:\",\n",
      "        \"output\": \"I'd be happy to help you with your questions about using social media in the workplace. Please go ahead and ask your questions, and I'll do my best to provide you with accurate and helpful information.\\n\\n(And just to confirm, I'll assume that you're looking for general guidance and not seeking specific advice tailored to a particular organization or individual. If you have specific context or requirements, feel free to let me know!)\"\n",
      "    },\n",
      "    {\n",
      "        \"instruction\": \"I'm looking for a reliable way to convert a video file to a different format.\",\n",
      "        \"output\": \"There are several ways to convert a video file to a different format, depending on your operating system and the specific formats you need to work with. Here are some reliable methods:\\n\\n1. Online Conversion Tools: Websites like Online-Convert.com, Convert.io, and Vidimpex allow you to upload your video file and choose the desired output format. These services are often free or low-cost and can handle a wide range of input and output formats.\\n2. Video Editing Software: Many video editing software programs, such as Adobe Premiere Pro, Final Cut Pro, and DaVinci Resolve, have built-in video conversion tools that allow you to convert files between different formats.\\n3. Handbrake: Handbrake is a free and open-source video transcoder that can convert files between various formats, including H.264, H.265, and ProRes. It's available for Windows, macOS, and Linux.\\n4. FFmpeg: FFmpeg is a powerful, open-source command-line tool that can convert, encode, and decode audio and video files. It's widely used in the film industry and can handle a wide range of input and output formats.\\n5. Freemake Video Converter: Freemake Video Converter is a free program for Windows that allows you to convert videos between various formats, including MP4, AVI, and MOV.\\n\\nRegardless of which method you choose, make sure to follow these best practices:\\n\\n* Always use reputable sources for video conversion software or online tools.\\n* Be aware of any file size or quality limitations when converting files.\\n* Test your converted files to ensure they play correctly on the desired device.\\n* Consider using a lossless conversion option if possible, such as Handbrake's \\\"lossless\\\" mode.\\n\\nRemember to always check the compatibility and compatibility requirements for the specific video format you're trying to convert.\"\n",
      "    },\n",
      "    {\n",
      "        \"instruction\": \"I'm looking for information on how to treat a cat with urinary tract infections (UTIs) in cats. If you could provide some general tips and advice, that would be greatly appreciated.\",\n",
      "        \"output\": \"Treating a cat with urinary tract infections (UTIs) requires prompt attention and proper care to prevent complications and ensure the best possible outcome. Here are some general tips and advice:\\n\\n**Diagnosis**\\n\\n1. Consult a veterinarian: If you suspect your cat has a UTI, take them to a veterinarian for a proper diagnosis. The vet will perform a physical examination, take a complete medical history, and run diagnostic tests such as urinalysis, blood work, or imaging studies (e.g., X-rays or ultrasound) to confirm the presence of a UTI.\\n\\n**Treatment**\\n\\n1. Antibiotics: The most common treatment for feline UTIs is antibiotics. Your veterinarian will prescribe a specific antibiotic based on the type and severity of the infection.\\n2. Pain management: Cats with UTIs may experience pain, so your veterinarian may recommend pain relief medication to help manage discomfort.\\n3. Fluid therapy: In some cases, cats with severe UTIs or those who are dehydrated may require intravenous fluid therapy to prevent dehydration.\\n\\n**Home Care**\\n\\n1. Provide a clean litter box: Make sure the litter box is clean and well-maintained to reduce the risk of bacterial recurrence. Scoop out solid waste daily, and change the litter completely every 7-10 days.\\n2. Feed a balanced diet: A high-quality commercial cat food with adequate moisture can help prevent UTIs. Consider feeding a food with added omega-3 fatty acids or antioxidants.\\n3. Encourage water intake: Offer your cat multiple water sources throughout the day to encourage drinking and help flush out bacteria from the urinary tract.\\n4. Monitor temperature: Cats with UTIs may exhibit elevated temperatures (pyrexia). If you notice a fever, contact your veterinarian for advice.\\n\\n**Prevention**\\n\\n1. Regular veterinary check-ups: Schedule regular check-ups with your veterinarian to monitor your cat's overall health and catch potential issues early.\\n2. Keep the litter box clean: Scoop out solid waste daily, and change the litter completely every 7-10 days to reduce bacterial growth.\\n3. Spay or neuter: Spaying or neutering can reduce the risk of UTIs in cats.\\n4. Provide a stress-free environment: Stress can exacerbate urinary issues. Ensure your cat has a comfortable and quiet living space.\\n\\n**When to Seek Emergency Care**\\n\\n1. Severe symptoms: If your cat exhibits severe symptoms such as vomiting, diarrhea, lethargy, or difficulty urinating, seek emergency care immediately.\\n2. Failure to respond to treatment: If your cat doesn't show improvement with antibiotics, consult your veterinarian for guidance on alternative treatments or additional support.\\n3. Recurring UTIs: If your cat experiences recurring UTIs, work closely with your veterinarian to develop a long-term management plan.\\n\\nRemember, every cat is different, and treatment may vary depending on the individual case. Consult with your veterinarian for personalized advice and care for your feline friend.\"\n",
      "    },\n",
      "    {\n",
      "        \"instruction\": \"Here is a text about the movie \\\"The Princess and the Frog\\\" (2009)\",\n",
      "        \"output\": \"I'm ready when you are. Please go ahead and share the text about the movie \\\"The Princess and the Frog.\\\"\"\n",
      "    }\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat instruction-data-llama3_2-3b.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f09018-1a53-4aa8-b33c-7bdea8426757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
